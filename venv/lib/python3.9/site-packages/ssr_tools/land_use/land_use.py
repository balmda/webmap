import geopandas as gpd
import pandas as pd
import os
from numpy import log
from ssr_tools.dbutils.dbutils import *

class LandUse(DBUtils):
    #TODO function for getting land use with greatest area within a buffer
    def __init__(self, lu, grid, uid_lc, uid_grid, temp_path,
                host='ssrc-db2.c9lbv7c8ir6a.us-east-2.rds.amazonaws.com', db_name=None, 
                user='postgres', password='g.&whu1*Q(Ndsn,j', port='5432', verbose=True):
        
        self.module_dir = os.path.dirname(os.path.abspath(__file__))
        self.verbose = verbose
        if self.verbose: print('Creating LandUse object')

        if db_name is not None:
            self.host = host
            self.db_name = db_name
            self.user = user 
            self.port = port
            self.password = password
            DBUtils.__init__(self, host=host, db_name=db_name, user=user, password=password, port=port,
                            verbose=verbose, filename=__file__)
        else: 
            raise ValueError('Need db connection info')

        self.lu = lu
        self.grid = grid
        self.uid_lc = uid_lc
        self.uid_grid = uid_grid
        self.temp_path = temp_path

        if self.verbose: print('successfully loaded base data.')
    
    def intermediate(self):
        intersection = gpd.overlay(self.lu,self.grid,how = 'intersection')
        dissolved = intersection.dissolve(by = [self.uid_lc,self.uid_grid])
    
        dissolved['poly_area'] = dissolved.area
        # dissolved.to_file(os.path.join(self.temp_path,"dissolved.shp"))
    
        dissolved_new = gpd.read_file(os.path.join(temp_path,"dissolved.shp"))
        area_sum = dissolved_new[[self.uid_grid, "poly_area"]].groupby(self.uid_grid).sum()
    
        dissolved_new = dissolved_new.merge(area_sum, on = self.uid_grid)
        dissolved_new.rename(columns = {'poly_area_y':'total_area_cell'}, inplace = True) 
    
        ratios = (dissolved_new["poly_area_x"]/dissolved_new["total_area_cell"])
        
        num_classes_per_grid_feature = dissolved_new[[self.uid_grid, uid_lc]].groupby(self.uid_grid).count()
        # dissolved_new.to_file(os.path.join(temp_path,"dissolved_new.shp"))
        return dissolved_new, ratios, num_classes_per_grid_feature, intersection
    
    def entropy(self, ent_table_name, ent_out_schema='automated', load_to_db=False):
        self.ent_table_name = ent_table_name
        self.ent_out_schema = ent_out_schema
        dataset = self.intermediate()[0]
        ratios_c = self.intermediate()[1]
        nuclapegrif=self.intermediate()[2]
        
        log_ratios = log(ratios_c)
        dataset['area_perc_log'] = log_ratios*ratios_c
        
        ln_num_classes_per_grid_feature = log(nuclapegrif)
        
        sum_logs = dataset[[self.uid_grid, "area_perc_log"]].groupby(self.uid_grid).sum()
        
        sum_logs_merged_ln_num_classes = sum_logs.merge(ln_num_classes_per_grid_feature,on = self.uid_grid)
        
        sum_logs_merged_ln_num_classes['ENTROPY'] = -1*(sum_logs_merged_ln_num_classes['area_perc_log']/sum_logs_merged_ln_num_classes[self.uid_lc])
        
        grid_final_entropy = (self.grid).merge(sum_logs_merged_ln_num_classes,on = self.uid_grid)
        print(grid_final_entropy['ENTROPY'])
        if load_to_db: 
            self.df_to_postgres(df=self.grid_final_entropy, 
                            temp_out_path = os.getcwd(), 
                            table_name= self.ent_table_name,
                            table_schema=self.ent_out_schema, 
                            if_exists='replace',
                            engine = self.create_db_con(db_name=self.db_name)[1], 
                            conn= self.create_db_con(db_name=self.db_name)[0])
            print('entropy data loaded to db')

        return grid_final_entropy
    
    def hhi(self, hhi_table_name, hhi_out_schema='automated', load_to_db=False):
        self.hhi_table_name = hhi_table_name
        self.hhi_out_schema = hhi_out_schema
        dataset = self.intermediate()[0]
        ratios_c = self.intermediate()[1]
        hhi = ((ratios_c))*2
        
        dataset['HHI'] = hhi
        
        sum_squared_ratios = dataset[[self.uid_grid, "HHI"]].groupby(self.uid_grid).sum()
        grid_final_hhi = (self.grid).merge(sum_squared_ratios,on = self.uid_grid)
        if load_to_db: 
            self.df_to_postgres(df=self.grid_final_entropy, 
                            temp_out_path = os.getcwd(), 
                            table_name= self.hhi_table_name,
                            table_schema=self.hhi_out_schema, 
                            if_exists='replace',
                            engine = self.create_db_con(db_name=self.db_name)[1], 
                            conn= self.create_db_con(db_name=self.db_name)[0])
            print('entropy data loaded to db')
        return grid_final_hhi

