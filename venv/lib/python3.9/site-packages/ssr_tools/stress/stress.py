#! /usr/bin/python

# Module for conducting level of traffic stress analysis on roadway datasets.
# Allows for flexible naming of columns via a config file.
import os, io
import psycopg2
from psycopg2 import sql
from psycopg2.extras import DictCursor
import yaml
import pandas as pd
import time

from lts_conf import Conf
from lts_dbutils import DBUtils

FORWARD_DIRECTION = "forward"
BACKWARD_DIRECTION = "backward"

class Stress(Conf):
    def __init__(self,config=None,create_lookups=True,host=None,db_name=None,
                 user=None,password=None,verbose=False):
        """
        Reads the config file, sets up a connection

        Parameters
        ----------
        config : str, optional
            path to the config file, if not given use the default config.yaml
        create_lookups : bool, optional
            creates lookup tables in the db if none are found
        host : str, optional
            host to connect to
        db_name : str, optional
            database name
        user : str, optional
            database user
        password : str, optional
            database password
        verbose : bool, optional
            output useful messages
        """
        Conf.__init__(self)
        self.verbose = verbose
        self.module_dir = os.path.dirname(os.path.abspath(__file__))
        if config is None:
            config = os.path.join(self.module_dir,"config.yaml")
        self.config = self.parse_config(yaml.safe_load(open(config)))
        print("Connecting to database")
        if host is None:
            host = self.config.db.host
        if db_name is None:
            db_name = self.config.db.dbname
        if user is None:
            user = self.config.db.user
        if password is None:
            password = self.config.db.password
        db_connection_string = " ".join([
            "dbname=" + db_name,
            "user=" + user,
            "host=" + host,
            "password=" + password
            ])
        DBUtils.__init__(self,db_connection_string,self.verbose,False)
        schema, table = self.parse_table_name(self.config.bna.network.roads.table)
        self.table = table
        if schema is None:
            self.schema = self.get_schema(self.table)
        else:
            self.schema = schema

        # check for and set lookup tables
        if self.verbose:
            print("Checking lookup tables")
        missing = self._missing_lookup_tables()
        if create_lookups and len(missing) > 0:
            if "units" in self.config:
                if self.config.units == "mi":
                    km = False
                elif self.config.units == "km":
                    km = True
                else:
                    raise ValueError("Invalid units \"{}\" in config".format(self.config.units))
            else:
                km = False
            for t in missing:
                self._create_lookup_table(*t)

        # add functions to db
        self._run_sql_script("bna_CompareAzimuths.sql",dict(),dirs=["sql","stress","db_functions"])
        self._run_sql_script("bna_IsCorridor.sql",dict(),dirs=["sql","stress","db_functions"])
        self._run_sql_script("bna_MultiEndPoint.sql",dict(),dirs=["sql","stress","db_functions"])
        self._run_sql_script("bna_MultiStartPoint.sql",dict(),dirs=["sql","stress","db_functions"])

        # build SQL substitutions
        self.segment_subs = dict()
        for direction in [FORWARD_DIRECTION,BACKWARD_DIRECTION]:
            self.segment_subs[direction] = self._build_segment_sql_substitutions(direction)
        
        self.crossing_subs = dict()
        for direction in [FORWARD_DIRECTION,BACKWARD_DIRECTION]:
            self.crossing_subs[direction] = self._build_crossing_sql_substitutions(direction)
        
        self.ped_crossing_subs = dict()
        self.ped_crossing_subs = self._build_ped_sql_substitutions()

        print('okay...stress.py is ready to go.')

    def _missing_lookup_tables(self):
        """
        Check for the lookup tables specified in the config file. Returns any
        missing tables as a tuple of (table type, table name)

        returns:
        list
        """
        missing = []
        for k, v in self.config.stress.lookup_tables.items():
            schema, table = self.parse_table_name(v)
            if not self.table_exists(table,schema):
                missing.append((k,table,schema))
                if self.verbose:
                    print("Table {} not identified, will create".format(v))
        return missing


    def _create_lookup_table(self,lu_type,table,schema=None,fname=None):
        """
        Create a stress lookup table of the given type and name

        Parameters
        ----------
        lu_type : ['shared', 'bike_lane', 'crossing', 'track']
            The type of lookup table to create
        table : str
            name of the table
        schema : str, optional
            name of the schema
        fname : str, optional
            optional csv file to populate the table with (if empty uses default)
        """
        if schema is None:
            schema = self.schema
        in_file = None
        if fname:
            if os.path.isfile(fname):
                in_file = fname
            else:
                raise ValueError("File not found at %s" % fname)

        if lu_type == "shared":
            columns = [
                ("condition", 'text'),
                ("criteria", 'text'),
                ("lanes", "integer"),
                ("marked_centerline", "boolean"),
                ("speed", "integer"),
                ("effective_aadt", "integer"),
                ("stress", "integer")
            ]
            if not in_file:
                in_file = os.path.join(self.module_dir,"sql","stress","tables",f"{table}.xlsx")
        elif lu_type == "bike_lane":
            columns = (
                ("condition", 'text'),
                ("criteria", 'text'),
                ("lanes", "integer"),
                ("parking", "boolean"),
                ("low_parking", "boolean"),
                ("reach", "integer"),
                ("speed", "integer"),
                ("stress", "integer")
            )
            if not in_file:
                in_file = os.path.join(self.module_dir,"sql","stress","tables",f"{table}.xlsx")
        elif lu_type == "crossing":
            columns = (
                ("condition", 'text'),
                ("criteria", 'text'),
                ("control", "text"),
                ("lanes", "integer"),
                ("speed", "integer"),
                ("island", "boolean"),
                ("oneway", "boolean"),
                ("aadt", "integer"),
                ("stress", "integer")
            )
            if not in_file:
                in_file = os.path.join(self.module_dir,"sql","stress","tables",f"{table}.xlsx")
         
        elif lu_type == "track":
            columns = (
                ("condition", 'text'),
                ("criteria", 'text'),
                ("separation_type", 'boolean'),
                ("lanes", "integer"),
                ("speed", "integer"),
                ("stress", "integer")
            )
            if not in_file:
                in_file = os.path.join(self.module_dir,"sql","stress","tables",f"{table}.xlsx")
        
        else:
            raise ValueError("Unrecognized lookup table %s" % lu_type)

        in_table = pd.read_excel(in_file)
        in_table = in_table.astype(str)
        conn = self.get_db_connection()
        self.gdf_to_postgis(in_table,table,schema=schema,no_geom=True,conn=conn)
        for col_name, col_type in columns:
            subs = {
                "schema": sql.Identifier(schema),
                "table": sql.Identifier(table),
                "col": sql.Identifier(col_name),
                "type": sql.SQL(col_type)
            }
            self._run_sql(
                """
                    update {schema}.{table} set {col} = null where {col} IN ('NaN','nan');
                    alter table {schema}.{table}
                        alter column {col} type {type} using {col}::{type};
                """,
                subs,
                conn=conn
            )
        conn.commit()
        conn.close()
        print(f'{lu_type} table is loaded and ready to go.')


    def segment_stress(self,table=None,table_filter=None,dry=None):
        """
        Creates a new table of LTS scores for each direction (forward/backward).
        The new table also includes the attributes (actual or assumed) that were
        used the calculate the LTS score.
        This is basically a pass-through function that calls several helpers to
        calculate the various parts

        Parameters
        ----------
        table : str, optional
            the table root (optionally schema-qualified) to use for outputting
            LTS scores. Final table name will have forward/backward appended to
            indicate the direction the score applies to. Defaults to "bna_stress_seg"
        table_filter : str, optional
            SQL filter to limit rows that should be updated
        dry : str, optional
            a path to save SQL statements to instead of executing in DB
        """
        print('starting segment stress...')
        seg_start_time = time.time()

        if table is None:
            schema = self.schema
            table = "bna_stress_seg"
        else:
            schema, table = self.parse_table_name(table)
            if schema is None:
                schema = self.schema      

        if table_filter:
            table_filter = sql.SQL(table_filter)
        else:
            table_filter = sql.SQL("TRUE")

        if not dry is None:
            if os.path.isfile(dry):
                raise ValueError("File already exists at {}".format(dry))

        conn = self.get_db_connection()
        try:
            for direction in [FORWARD_DIRECTION,BACKWARD_DIRECTION]:
                if self.verbose:
                    print("  ....{}".format(direction))

                # create output table
                subs = self.segment_subs[direction].copy()
                subs["fclass_column"] = sql.Identifier(self.config.bna.network.roads.fclass)
                subs["out_schema"] = sql.Identifier(schema)
                subs["out_table"] = sql.Identifier("_".join([table,direction]))
                self._run_sql_script("create_output.sql",subs,dirs=["sql","stress","segment"],conn=conn)

                # call the various segment stress methods
                self._segment_stress_shared(conn,subs,table_filter)
                self._segment_stress_bike_lane(conn,subs,table_filter)                
                self._segment_stress_track(conn,subs,table_filter)
                self._segment_stress_path(conn,subs,table_filter)
                
                # copy back to the base table
                print("....copying back to base")
                step_time = time.time()
                subs["stress"] = sql.Identifier(self.config.bna.network.roads.stress.segment[direction])
                self._run_sql_script("copy_to_base.sql",subs,dirs=["sql","stress"],conn=conn)
                print(f"....step time: {round(((time.time() - step_time)/60),2)} minutes.")

        except Exception as e:
            if conn.closed == 0:
                conn.rollback()
                conn.close()
            raise e

        conn.commit()
        conn.close()
        print(f"....overall segment stress time: {round(((time.time() - seg_start_time)/60),2)}")
        print('    ....Segment Stress Done')


    def _segment_stress_shared(self,conn,subs,table_filter=None,dry=None):
        """
        Calculates segment stress for shared lanes

        Parameters
        ----------
        conn : psycopg2 connection object
            a psycopg2 connection object
        subs : dict
            mappings of column names from the config file
        table_filter : str, optional
            filter to limit rows that should be updated
        dry : str, optional
            a path to save SQL statements to instead of executing in DB
        """
        print("Calculating stress on shared streets")

        # filter
        if table_filter is None:
            table_filter = sql.SQL("TRUE")

        subs["filter"] = table_filter

        # execute the query
        step_time = time.time()
        self._run_sql_script("shared.sql",subs,dirs=["sql","stress","segment"],conn=conn)
        print(f"....step time: {round(((time.time() - step_time)/60),2)} minutes.")


    def _segment_stress_bike_lane(self,conn,subs,table_filter=None,dry=None):
        """
        Calculates segment stress for bike lanes
        (includes buffered lanes)

        Parameters
        ----------
        conn : psycopg2 connection object
            a psycopg2 connection object
        subs : dict
            mappings of column names from the config file
        table_filter : str, optional
            filter to limit rows that should be updated
        dry : str, optional
            a path to save SQL statements to instead of executing in DB
        """
        print("Calculating stress on streets with bike lanes")

        # filter
        if table_filter is None:
            table_filter = sql.SQL("TRUE")

        subs["filter"] = table_filter

        # execute the query
        step_time = time.time()
        self._run_sql_script("bike_lane.sql",subs,dirs=["sql","stress","segment"],conn=conn)
        print(f"....step time: {round(((time.time() - step_time)/60),2)} minutes.")

    def _segment_stress_track(self,conn,subs,table_filter=None,dry=None):
        """
        Calculates segment stress for cycle tracks

        Parameters
        ----------
        conn : psycopg2 connection object
            a psycopg2 connection object
        subs : dict
            mappings of column names from the config file
        table_filter : str, optional
            filter to limit rows that should be updated
        dry : str, optional
            a path to save SQL statements to instead of executing in DB
        """
        print("Calculating stress on streets with cycle tracks")

        # filter
        if table_filter is None:
            table_filter = sql.SQL("TRUE")

        subs["filter"] = table_filter

        # execute the query
        step_time = time.time()
        self._run_sql_script("track.sql",subs,dirs=["sql","stress","segment"],conn=conn)
        print(f"....step time: {round(((time.time() - step_time)/60),2)} minutes.")

    def _segment_stress_path(self,conn,subs,table_filter=None,dry=None):
        """
        Calculates segment stress for cycle tracks

        Parameters
        ----------
        subs : dict
            mappings of column names from the config file
        table_filter : str, optional
            filter to limit rows that should be updated
        dry : str, optional
            a path to save SQL statements to instead of executing in DB
        """
        print("Calculating stress on paths")

        # filter
        if table_filter is None:
            table_filter = sql.SQL("TRUE")

        subs["filter"] = table_filter

        # execute the query
        step_time = time.time()
        self._run_sql_script("path.sql",subs,dirs=["sql","stress","segment"],conn=conn)
        print(f"....step time: {round(((time.time() - step_time)/60),2)} minutes.")

    def crossing_stress(self,table=None,angle=20,table_filter=None,dry=None):
        """
        Calculates stress for crossings

        Parameters
        ----------
        table : str, optional
            the table root (optionally schema-qualified) to use for outputting
            LTS scores. Final table name will have forward/backward appended to
            indicate the direction the score applies to. Defaults to "bna_stress_cross".
        angle : int or float
            the angle that determines whether a connection from
                    one road to another constitutes a crossing
        table_filter : str, optional
            filter to limit rows that should be updated
        dry : str, optional
            a path to save SQL statements to instead of executing in DB
        """
        crossing_start_time = time.time()

        if table is None:
            schema = self.schema
            table = "bna_stress_cross"
        else:
            schema, table = self.parse_table_name(table)
            if schema is None:
                schema = self.schema

        conn = self.get_db_connection()
        try:
            for direction in [FORWARD_DIRECTION,BACKWARD_DIRECTION]:
                print("  ....{}".format(direction))

                cross_subs = self.crossing_subs[direction].copy()
                cross_subs["out_schema"] = sql.Identifier(schema)
                cross_subs["out_table"] = sql.Identifier("_".join([table,direction]))
                cross_subs["angle"] = sql.Literal(angle)
                cross_subs["point"] = sql.Identifier("_".join([direction,"pt"]))
                cross_subs["line"] = sql.Identifier("_".join([direction,"ln"]))

                # execute the query
                step_time = time.time()
                self._run_sql_script("01_create_output.sql",cross_subs,dirs=["sql","stress","crossing"],conn=conn)
                print(f"....01_create_output step time: {round(((time.time() - step_time)/60),2)} minutes.")

                step_time = time.time()
                self._run_sql_script("02_inputs.sql",cross_subs,dirs=["sql","stress","crossing"],conn=conn)
                print(f"....02_inputs step time: {round(((time.time() - step_time)/60),2)} minutes.")

                step_time = time.time()
                self._run_sql_script("03_crossing.sql",cross_subs,dirs=["sql","stress","crossing"],conn=conn)
                print(f"....03_crossing step time: {round(((time.time() - step_time)/60),2)} minutes.")

                # step_time = time.time()
                # self._run_sql_script("04_priority.sql",cross_subs,dirs=["sql","stress","crossing"],conn=conn)
                # print(f"....04_priority step time: {round(((time.time() - step_time)/60),2)} minutes.")

                # copy back to the base table
                cross_subs["stress"] = sql.Identifier(self.config.bna.network.roads.stress.crossing[direction])
                self._run_sql_script("copy_to_base.sql",cross_subs,dirs=["sql","stress"],conn=conn)
                print(f"....copy_to_base step time: {round(((time.time() - step_time)/60),2)} minutes.")
                step_time = time.time()

        except Exception as e:
            if conn.closed == 0:
                conn.rollback()
                conn.close()
            raise e

        conn.commit()
        conn.close()
        print(f"....crossing time: {round(((time.time() - crossing_start_time)/60),2)} minutes.")
        print('    ....Crossing Stress Done')
    
    def ped_crossing_stress(self,table=None,table_filter=None,dry=None):
        """
        Calculates stress for ped crossings

        Parameters
        ----------
        table : str, optional
            the table root (optionally schema-qualified) to use for outputting
            LTS scores. Final table name will have forward/backward appended to
            indicate the direction the score applies to. Defaults to "bna_stress_cross".
        angle : int or float
            the angle that determines whether a connection from
                    one road to another constitutes a crossing
        table_filter : str, optional
            filter to limit rows that should be updated
        dry : str, optional
            a path to save SQL statements to instead of executing in DB
        """
        crossing_start_time = time.time()

        if table is None:
            schema = self.schema
            table = "bna_stress_ped_cross"
        else:
            schema, table = self.parse_table_name(table)
            if schema is None:
                schema = self.schema
        
        

        conn = self.get_db_connection()
        try:
            print("  ....starting ped crossing stress")

            ped_cross_subs = self.ped_crossing_subs.copy()
            ped_cross_subs["out_schema"] = sql.Identifier(schema)
            ped_cross_subs["out_table"] = sql.Identifier(table)
            
            # filter
            if table_filter is None:
                table_filter = sql.SQL("TRUE")

            ped_cross_subs["filter"] = table_filter

            # execute the query
            step_time = time.time()
            self._run_sql_script("10_create_ped_output.sql",ped_cross_subs,dirs=["sql","stress","crossing"],conn=conn)
            print(f"....10_create_ped_output step time: {round(((time.time() - step_time)/60),2)} minutes.")

            self._run_sql_script("11_ped_crossing.sql",ped_cross_subs,dirs=["sql","stress","crossing"],conn=conn)
            print(f"....11_ped_crossing step time: {round(((time.time() - step_time)/60),2)} minutes.")

            # copy back to the base table
            ped_cross_subs["stress"] = sql.Identifier(self.config.bna.network.ped_crossings.stress)
            self._run_sql_script("copy_to_base.sql",ped_cross_subs,dirs=["sql","stress"],conn=conn)
            print(f"....copy_to_base step time: {round(((time.time() - step_time)/60),2)} minutes.")
            step_time = time.time()

        except Exception as e:
            if conn.closed == 0:
                conn.rollback()
                conn.close()
            raise e

        conn.commit()
        conn.close()
        print(f"....ped crossing time: {round(((time.time() - crossing_start_time)/60),2)} minutes.")
        print('    ....Ped Crossing Stress Done')
    
    def temp_crossing_stress(self,conn,table_filter=None,dry=None):
        """

        """
        print("Calculating stress for crossings using temp approach")
        conn = self.get_db_connection()
        # execute the query
        step_time = time.time()
        self._run_sql_script("20_bike_ped_stress.sql", subs= dict(), dirs=["sql","stress","crossing"],conn=conn)
        print(f"....step time: {round(((time.time() - step_time)/60),2)} minutes.")
