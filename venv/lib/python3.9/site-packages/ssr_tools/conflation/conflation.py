import os
import pandas as pd 
import psycopg2
from psycopg2 import sql
from ssr_tools.dbutils.dbutils import DBUtils 
from ssr_tools.dbutils.dbutils import *
import time

class Conflation(DBUtils):
    def __init__(self, host='ssrc-db2.c9lbv7c8ir6a.us-east-2.rds.amazonaws.com', db_name=None, 
                user='postgres', password='g.&whu1*Q(Ndsn,j', port='5432', verbose=True):
        """
        Initiates an object to produce a conflate two features.

        Args:
            verbose (bool, optional): Want some outputs to tell you what the script is doing? Yes? Set to true. Else, set to false. Defaults to True.
            host (str, optional): postgres host string. Defaults to 'ssrc-db1.c9lbv7c8ir6a.us-east-2.rds.amazonaws.com'.
            db_name (string, optional): name of the database in which the data is stored and being exported to. Defaults to None.
            user (str, optional): postgres username. Defaults to 'postgres'.
            password (str, optional): _description_. postgres password to 'g.&whu1*Q(Ndsn,j'.
            port (str, optional): postgres port. Defaults to '5432'.
        """
        self.dir = os.path.dirname(os.path.abspath(__file__))
        self.sql_dir = os.path.join(self.dir, 'sql')

        self.verbose = verbose
        if self.verbose: print('Creating Conflation object')
        
        if db_name is not None:
            self.host = host
            self.db_name = db_name
            self.user = user 
            self.port = port
            self.password = password
            DBUtils.__init__(self, host=self.host, db_name=self.db_name, user=self.user, 
                            password=self.password, port=self.port,
                            verbose=self.verbose, filename=__file__)

    def conflate(self, table, target_table, source_table, source_column,
                 tolerance, min_length=0, max_score=999, max_angle=90,
                 target_filter=None, source_filter=None, target_geom=None,
                 source_geom=None, overwrite=False, conn=None):
        """ 
        General conflation script. Very much in the works. 
        TODO add function to join back to main target table 
        TODO assign score to output table 
        TODO all arg for all fields to be joined from source to target, so it's not just the pkey

        Args:
            table (string): output table name and schema. 
            target_table (string): input table for the target table (i.e. automated.segments). This table has to be a linestring. 
            source_table (string): table with the attributes you want conflated to target table.
            source_column (string): name of the source table geom column.
            tolerance (int): max distance between source and target pair candidates.
            min_length (int, optional): min length for input target features. Defaults to 0.
            max_score (int, optional): max haussdorf score for candidates. The higher the score, the worse the match. Defaults to 999.
            max_angle (int, optional): max angle between pairs to be considered a match candidate. Defaults to 90.
            target_filter (string, optional): filter to apply to the target table. Defaults to None.
            source_filter (string, optional): filter to apply to the source table. Defaults to None.
            target_geom (string, optional): name of geometry column for target table. Defaults to None.
            source_geom (string, optional): name of geometry column for source table. Defaults to None.
            overwrite (bool, optional): overwrite out? Defaults to False.
            conn (string, optional): psycopg2 connection to db. Defaults to None.

        """
        start_time = time.time()

        if conn is None:
            if self.db_name is None: 
                self.conn = self.create_db_con(self.db_name)[0]
            else:
                self.conn = self.create_db_con(self.db_name)[0]
        #------------------------
        # table info
        if self.verbose: print('setting up table and schema info.')
        # parse tables for schemas
        self.schema, self.table = self.parse_table_name(name=table)
        if self.schema is None:
            self.schema = target_schema

        if source_column is None: 
            raise ValueError("need to provide a source_column.")
        else: 
            self.source_column=source_column
        
        self.target_schema, self.target_table = self.parse_table_name(name=target_table)
        self.source_schema, self.source_table = self.parse_table_name(name=source_table)
        
        if (not overwrite) and self.does_table_exists(table=self.table,schema=self.schema):
            raise ValueError("Table {}.{} already exists".format(self.schema, self.table))
        
        # get geoms
        if target_geom is None:
            self.target_geom = self.get_geom_column(self.target_table,self.target_schema,"linestring")
        else: 
            self.target_geom = target_geom
        if source_geom is None:
            self.source_geom = self.get_geom_column(self.source_table,self.source_schema)
        else: 
            self.source_geom = source_geom
        # test for multi target
        if self.check_multi(table=self.target_table,schema=self.target_schema,geom=self.target_geom):
            raise ValueError("Target table cannot be a multilinestring")

        # primary keys
        self.target_pkid = self.get_pkey(self.target_table,self.target_schema)
        self.source_pkid = self.get_pkey(self.source_table,self.source_schema)
        if self.target_pkid is None:
            raise ValueError("No primary key on target table")
        if self.source_pkid is None:
            raise ValueError("No primary key on source table")

        #-----------------------
        # tool params
        # set filters
        if target_filter is None:
            self.target_filter = sql.SQL("TRUE")
        else:
            self.target_filter = sql.SQL(target_filter)
        
        if source_filter is None:
            self.source_filter = sql.SQL("TRUE")
        else:
            self.source_filter = sql.SQL(source_filter)

        if tolerance is None:
            self.tolerance = float(input("***You didn't indicate a tolerate, please provide one: ").strip())
        else:
            self.tolerance = tolerance
        
        if min_length is None:
            self.min_length = float(input("***You didn't indicate a min_length, please provide one: ").strip())
        else:
            self.min_length = min_length
        
        if max_score is None:
            self.max_score = float(input("***You didn't indicate a max_score, please provide one: ").strip())
        else:
            self.max_score = max_score
        
        if max_angle is None:
            self.max_angle = float(input("***You didn't indicate a max_angle, please provide one: ").strip())
        else:
            self.max_angle = max_angle

        # set up sql substitutions
        self.subs = {
            "schema": sql.Identifier(self.schema),
            "table": sql.Identifier(self.table),

            "target_schema": sql.Identifier(self.target_schema),
            "target_table": sql.Identifier(self.target_table),
            "target_pkid": sql.Identifier(self.target_pkid),
            "target_geom": sql.Identifier(self.target_geom),
            "target_filter": self.target_filter,

            "source_schema": sql.Identifier(self.source_schema),
            "source_table": sql.Identifier(self.source_table),
            "source_pkid": sql.Identifier(self.source_pkid),
            "source_geom": sql.Identifier(self.source_geom),
            "source_column": sql.Identifier(self.source_column),
            "source_filter": self.source_filter,

            "tolerance": sql.Literal(self.tolerance),
            "min_length": sql.Literal(self.min_length),
            "max_score": sql.Literal(self.max_score),
            "max_angle": sql.Literal(self.max_angle)
            }

        try:
            if overwrite:
                if self.verbose: print('overwrite == True: dropping table if it exists')

                self.drop_table(table=self.table,schema=self.schema)
            
            if self.verbose: print('Running conflation queries')
            self.execute_sql_script(
                file_name='conflate.sql',
                subs=self.subs,
                db_name=self.db_name,
                commit_changes=True)

            if self.verbose: 
                print(f"Time to process: {round(((time.time() - start_time)/60),2)} minutes.\n")
                print('my job here is done')
        
        except Exception as e:
            print(f"Time spent before error: {round(((time.time() - start_time)/60),2)} minutes.\n")
            raise e
